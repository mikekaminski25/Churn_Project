---
title: "Churn Example Models"
author: "Mike Kaminski"
date: "2023-11-20"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Libraries and Load Data
```{r libraries}
library(tidymodels)
tidymodels_prefer()
```

```{r data_load}
data <- read.csv("C:/Users/mikek/Downloads/WA_Fn-UseC_-Telco-Customer-Churn.csv")
```

# Initial Data Review
```{r}
summary(data)
```
  * Many of the columns have character values, but they should really be factors
  * customerID isn't needed for modeling purposes, but it's worth including in the data frame for now in case research needs to done after modeling is complete
  * SeniorCitizens is numeric, but it should be a character/factor
  * Total Charges appears to be the product of MonthlyCharges and Tenure

## Update the data
- Updated various values in various cells and fixed NAs
```{r}
df_churn <- data |>
  
  # update SeniorCitizen to a character value
  mutate(SeniorCitizen = ifelse(SeniorCitizen == 0, "No","Yes")) |>
  
  # replace NAs in TotalCharges with 0.  When filtering the NAs, all these customers had a tenure of 0, meaning they haven't paid anything...yet
  mutate(TotalCharges = ifelse(is.na(TotalCharges),0,TotalCharges)) |>
  
  # I also want to create variables for Phone Only, Internet Only, or Both
  mutate(Package = ifelse(PhoneService %in% 'Yes' & InternetService %in% 'No', 'PhoneOnly',
                          ifelse(InternetService %in% c('DSL','Fiber Optic') & PhoneService %in% 'No', 'InternetOnly','Both'))
         ) |>

  # Put Churn at the front
  select(Churn,everything())
```
  
```{r}
test <-  df_churn |>
  mutate(across(where(is.character), as.factor))|>
  select(-customerID)

as.data.frame(model.matrix(~0+ ., data = test) |> cor(use="pairwise.complete.obs"))

```
  
  
  
```{r}
# Now I'd like to see which features are most correlated with Churn

# this code creats a matrix by expanding factor variables to a set of dummy variables
churn_corr <- as.data.frame(model.matrix(~., data = df_churn |> select(-customerID))) |> select(-1)

m <- cor(churn_corr)

m_churn <- m['ChurnYes', ]

m_churn_df <- data.frame(variable = names(m_churn), correlation = m_churn)

m_churn_df |> 
  filter(variable != 'ChurnYes') |>
  ggplot(aes(x = reorder(variable,-correlation), y = correlation)) +
  geom_bar(stat = "identity", position = "identity", fill = 'steelblue') +
  geom_text(aes(label = sprintf("%.3f", correlation)), vjust = -0.5) +
  labs(title = 'Correlation with Churn', y = 'Correlation',x = 'Variable') +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 10)) +
  scale_y_continuous(limits = c(-0.4, 0.4), breaks = seq(-0.4, 0.4, by = 0.1))

```
From this bar plot, we can see that Fiber Optic Internet customers and customer who pay by electronic check have a positive correlation with Churn, while customers with a longer tenure and customers with a contract of two-years have a negative correlation with Churn

```{r}
# Fiber Optic internet is easily the most common
df_churn %>%
    ggplot(aes(x = InternetService, fill = InternetService)) +
    geom_bar() +
    theme(legend.position="none") +
    labs(x ="") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

# Electronic Check is the most common payment method
df_churn %>%
    ggplot(aes(x = PaymentMethod, fill = PaymentMethod)) +
    geom_bar() +
    theme(legend.position="none") +
    labs(x ="") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

# Fiber Optic by Electronic Check is by far the most common
df_churn %>%
    ggplot(aes(x = PaymentMethod, fill = PaymentMethod)) +
    geom_bar() +
    facet_wrap(vars(InternetService)) +
    theme(legend.position="none") +
    labs(x ="") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

# much of the churn appears to come from Fiber Optic customer who pay by electronic check. Might be worth exploring
    ggplot(aes(x = PaymentMethod, fill = PaymentMethod)) +
    geom_bar() +
    facet_wrap(vars(Churn, InternetService)) +
    theme(legend.position="none") +
    labs(x ="") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

```{r}
# There are a lot of shorter tenures
df_churn %>%
    ggplot(aes(x = tenure)) +
    geom_bar(color = "blue") +
    theme(legend.position="none") +
    labs(x ="") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

# Month-to-month is the most common contract
df_churn %>%
    ggplot(aes(x = Contract, fill = Contract)) +
    geom_bar() +
    theme(legend.position="none") +
    labs(x ="") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

# Month-to-month have shorter tenures, two year contracts have longer tenures
df_churn %>%
    ggplot(aes(x = tenure)) +
    geom_bar(color = "blue") +
    facet_wrap(vars(Contract)) +
    theme(legend.position="none") +
    labs(x ="") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

# much of the churn appears to come from month to month clients with a shorter tenure
df_churn %>%
    ggplot(aes(x = tenure)) +
    geom_bar(color = "blue") +
    facet_wrap(vars(Churn, Contract)) +
    theme(legend.position="none") +
    labs(x ="") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

```
# Modeling

There are a few different models I want to look at for predicting Churn
  * Logistic Regression
  * Random Forest
  * xgBoost
  * KNN
  * SVM

I'll explore splitting the data using a strata split based on Churn - given that it's slightly imbalance - and cross-validation - which rarely hurts and often helps.
```{r}
model_df <- df_churn |> mutate_if(is.character, as.factor) |> mutate(customerID = as.character(customerID))
# changing to factors
```

## Setting up the split and crossvalidation  
```{r}
set.seed(21425)
churn_split <- initial_split(model_df, strata = Churn)
churn_train <- training(churn_split)
churn_test <- testing(churn_split)

# I'll set up crossfold validation for use later if the results aren't great
set.seed(1502)
churn_folds <- 
   vfold_cv(churn_train, strata = Churn)
```

## Recipe
```{r}
model_recipe <- 
  recipe(Churn ~ ., churn_train) |>
  
  # keeps the custID in case we have to explore a specific customer
  update_role(customerID, new_role = "ID") |> # keeps the custID in case we have to explore a specific customer
  
  # creates dummy variables
  step_dummy(all_nominal_predictors()) |> # this will exclude the outcome variable ()
  
  # removes variables with zero variance, if any
  step_zv(all_predictors()) |>
  
  # Normalize the data for regularization
  step_normalize(all_numeric_predictors())

```


## Building Model Specifications
I want to use glmnet for penalized logistic regression, random forest, xgBoost, K-nearest neighbor, and support vector machines for my models
For all of these models - except for glmnet - I need to specify the mode - classification
```{r}
glm_spec <-
  logistic_reg(penalty = tune(), # range from -10, 0 - represents the amount of the penalty
               mixture = tune() # range from 0,1 represents the relative amount of penalties
                        ) %>% 
  set_engine("glmnet")

rf_spec <- 
   rand_forest(mtry = tune(), 
               min_n = tune(), 
               trees = 1000
               ) %>% 
   set_engine("ranger") %>% 
   set_mode("classification")

xgb_spec <- 
   boost_tree(tree_depth = tune(), 
              learn_rate = tune(), 
              loss_reduction = tune(), 
              min_n = tune(), 
              sample_size = tune(), 
              trees = tune()) %>% 
   set_engine("xgboost") %>% 
   set_mode("classification")

knn_spec <- 
   nearest_neighbor(neighbors = tune(), 
                    dist_power = tune(), 
                    weight_func = tune()) %>% 
   set_engine("kknn") %>% 
   set_mode("classification")

svm_spec <- 
   svm_rbf(cost = tune(), 
           rbf_sigma = tune()) %>% 
   set_engine("kernlab") %>% 
   set_mode("classification")

```


## Create a workflow
I can create a workflow set that runs all these at once, but I think it would be useful to do at least one to see how the process flows
```{r}
glmnet_wf <- 
  workflow() |> 
  add_model(glm_spec) |>
  add_recipe(model_recipe)
```

### For glmnet, I want to create a grid for tuning and then apply to the model
Levels of 5 indicate that a 5x5 matrix will be created
```{r}
glmnet_grid <- grid_regular(penalty(range()),
                          mixture(),
                          levels = 5)

```

```{r}
set.seed(345)

glmnet_res <- 
  glmnet_wf %>% 
  tune_grid(
    resamples = churn_folds,
    control = control_grid(save_pred = TRUE),
    grid = glmnet_grid
    )

# lr_res$splits[[1]]
```

```{r}
glmnet_res |>
  collect_metrics() |>
  filter(.metric == "roc_auc") |>
  arrange(-mean,penalty, mixture)
```

```{r}
glmnet_res %>%
  collect_metrics() %>%
  mutate(mixture = factor(mixture)) %>%
  ggplot(aes(penalty, mean, color = mixture)) +
  geom_line(size = 1.5, alpha = 0.6) +
  geom_point(size = 2) +
  facet_wrap(~ .metric, scales = "free", nrow = 2) +
  scale_x_log10(labels = scales::label_number()) +
  scale_color_viridis_d(option = "plasma", begin = .9, end = 0)
```

Lower penalties seem to do well, however mixture isn't quite as clear - they're all around 83-84%.  I can re-tune with a small penalty range
```{r}
glmnet_grid <- grid_regular(penalty(range = c(-10,-5)), # range is -10 to 0 and on the log scale
                          mixture(),
                          levels = 5)

set.seed(345)

glmnet_res <- 
  glmnet_wf %>% 
  tune_grid(
    resamples = churn_folds,
    control = control_grid(save_pred = TRUE),
    grid = glmnet_grid
    )

glmnet_res |>
  collect_metrics() |>
  filter(.metric == "roc_auc") |>
  arrange(-mean,penalty, mixture)

```

Not much of an improvement, but I can still use the newly tuned values
```{r}
best_glmnet <- glmnet_res %>%
  select_best("roc_auc")
best_glmnet
```

#### Final Model
Creating a workflow using the best penalty and mixture - a low penalty and a pure lasso regularization
```{r}
final_wf <- 
  glmnet_wf %>% 
  finalize_workflow(best_glmnet)
```

Metrics and ROC curve
* last_fit() emulates the process where, after determining the best model - aka from final_wf, the final fit on the entire training set is needed and is then evaluated on the test set.
```{r warning=FALSE}
final_fit <- 
  final_wf %>%
  last_fit(churn_split) 

final_fit %>%
  collect_metrics()

final_fit %>%
  collect_predictions() %>% 
  roc_curve(Churn, .pred_No) %>% 
  autoplot()
```
Best roc_auc is 85.8

### Random Forest

#### Create the workflow
```{r}
rf_workflow <- 
  workflow() |> 
  add_model(rf_spec) |>
  add_recipe(model_recipe)
```

#### Train Hyperparameters
This will be trained a bit differently than the penalized logistic regression.  RF models tend to perform well without tuning, but it doesn't hurt to explore a bit.  I won't use grid regular as with glmnet, but the tuning process is more or less the same., just takes a lot longer
```{r}
doParallel::registerDoParallel()

set.seed(345)
rf_tune <- tune_grid(
  rf_workflow,
  resamples = churn_folds,
  grid = 20
)

# rf_tune$.metrics
```

```{r}
rf_tune |> collect_metrics() 
rf_tune |> select_best()
```

```{r}
rf_tune %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "AUC")
```
Generally it looks like higher min_n and lower mtry, so defining ranges for each and re-tuning

```{r}
rf_grid <- grid_regular(
  mtry(range = c(0, 11)),
  min_n(range = c(30, 40)),
  levels = 5
)
```

```{r}
set.seed(456)
rf_tune <- tune_grid(
  rf_workflow,
  resamples = churn_folds,
  grid = rf_grid
)

rf_tune %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  mutate(min_n = factor(min_n)) %>%
  ggplot(aes(mtry, mean, color = min_n)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "AUC")

```
An mtry of 5 and min_n of 40 

```{r}
best_auc <- select_best(rf_tune, "roc_auc")

final_rf <- finalize_model(
  rf_spec,
  best_auc
)
final_rf

```
```{r}
library(vip)

final_rf %>%
  set_engine("ranger", importance = "permutation") %>%
  fit(Churn ~ .,
    data = juice(prep(model_recipe)) %>% select(-customerID)
  ) %>%
  vip(geom = "point")
```
Tenure and TotalCharges are important, but they're definitely correlated - TotalCharges is the product of tenure and MonthlyCharges.  Fiber Optic is also important as well as Monthly Charges - which by itself is a good indicator


```{r}
final_wf <- 
  workflow() %>%
  add_recipe(model_recipe) %>%
  add_model(final_rf)

final_res <- final_wf %>%
  last_fit(churn_split)

final_res %>%
  collect_metrics()
```
ROC_AUC is 85.3, worse than regularized logistic (85.8)
